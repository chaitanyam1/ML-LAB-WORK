{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML lab 10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMFO6b1bccz6YBmDtiOX0t/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaitanyam1/ML-LAB-WORK/blob/master/ML_lab_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0Vxs4RaFNJo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import numpy as np\n",
        "#from sklearn import preprocessing, cross_validation\n",
        "import pandas as pd\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRVdwEaQD7y_",
        "colab_type": "text"
      },
      "source": [
        "**Question** **2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-t52FA7zEASW",
        "colab_type": "text"
      },
      "source": [
        "Generation of Random data for Mutliple linear regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRU9JvfGE0ES",
        "colab_type": "code",
        "outputId": "daa2f3b4-1ea2-41f0-f7fa-0e3a9d50c45e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import random\n",
        "from scipy.stats import norm\n",
        "random.seed(1)\n",
        "n_features = 4\n",
        "X = []\n",
        "for i in range(n_features):\n",
        "  X_i = scipy.stats.norm.rvs(0, 1, 100)\n",
        "  X.append(X_i)\n",
        "#print(X)\n",
        "eps = scipy.stats.norm.rvs(0, 0.05,100)\n",
        "y = 1 + (0.5 * X[0]) + eps + (0.4 * X[1]) + (0.3 * X[2]) + (0.5 * X[3])\n",
        "data_mlr = {'X0': X[0],'X1':X[1],'X2':X[2],'X3':X[3],'Y': y }\n",
        "mlrdf = pd.DataFrame(data_mlr)\n",
        "print(mlrdf.head())\n",
        "print(mlrdf.tail())\n",
        "print(mlrdf.info())\n",
        "print(mlrdf.describe())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         X0        X1        X2        X3         Y\n",
            "0 -1.069336 -0.951333 -1.390779  0.205790 -0.214075\n",
            "1 -0.723615 -0.109126  0.296455  0.094432  0.792768\n",
            "2 -0.431207 -0.719126  1.061457 -0.265630  0.717330\n",
            "3  0.235615  0.315925 -2.190793 -0.679635  0.232124\n",
            "4 -1.310578 -0.986769  0.078762  0.028389  0.022819\n",
            "          X0        X1        X2        X3         Y\n",
            "95 -0.059326  0.779440 -0.313398 -0.178615  1.114869\n",
            "96 -0.547268 -1.579254  0.078614 -0.588001 -0.237102\n",
            "97  1.054542  0.782547  2.077024 -1.407069  1.746923\n",
            "98 -0.039729  0.247937  0.435073  0.477731  1.451447\n",
            "99  0.058581 -0.780989  2.234854 -1.303513  0.808680\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   X0      100 non-null    float64\n",
            " 1   X1      100 non-null    float64\n",
            " 2   X2      100 non-null    float64\n",
            " 3   X3      100 non-null    float64\n",
            " 4   Y       100 non-null    float64\n",
            "dtypes: float64(5)\n",
            "memory usage: 4.0 KB\n",
            "None\n",
            "               X0          X1          X2          X3           Y\n",
            "count  100.000000  100.000000  100.000000  100.000000  100.000000\n",
            "mean    -0.128507   -0.077860   -0.056483    0.063189    0.915324\n",
            "std      1.032848    0.973315    1.032571    0.985710    0.856616\n",
            "min     -2.912752   -2.891103   -2.274049   -3.004090   -1.224355\n",
            "25%     -0.936735   -0.726124   -0.742671   -0.477317    0.393633\n",
            "50%     -0.055788   -0.073508    0.045050    0.092534    0.898697\n",
            "75%      0.640501    0.729716    0.652070    0.594945    1.488310\n",
            "max      3.004280    1.724499    2.527194    2.816770    2.766601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyncXXmRELcZ",
        "colab_type": "text"
      },
      "source": [
        "Data generation for logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDCrXiMbFALw",
        "colab_type": "code",
        "outputId": "82c904c1-43f6-4d57-a7eb-8b5392db4662",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        }
      },
      "source": [
        "n_features = 4\n",
        "X = []\n",
        "for i in range(n_features):\n",
        "  X_i = scipy.stats.norm.rvs(0, 1, 100)\n",
        "  X.append(X_i)\n",
        "\n",
        "a1 = (np.exp(1 + (0.5 * X[0]) + (0.4 * X[1]) + (0.3 * X[2]) + (0.5 * X[3]))/(1 + np.exp(1 + (0.5 * X[0]) + (0.4 * X[1]) + (0.3 * X[2]) + (0.5 * X[3]))))\n",
        "\n",
        "y = []\n",
        "for i in a1:\n",
        "  if (i>=0.5):\n",
        "    y.append(1)\n",
        "  else:\n",
        "    y.append(0)\n",
        "\n",
        "data_lr = {'X0': X[0],'X1':X[1],'X2':X[2],'X3':X[3],'Y': y }\n",
        "lrdf = pd.DataFrame(data_lr)\n",
        "print(lrdf.head())\n",
        "print(lrdf.tail())\n",
        "print(lrdf.info())\n",
        "print(lrdf.describe())\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         X0        X1        X2        X3  Y\n",
            "0  0.141498  0.150373  2.104571  2.166023  1\n",
            "1  0.895225  0.269286 -1.087725 -1.725060  1\n",
            "2 -0.529124  1.958292  0.241137  0.635728  1\n",
            "3  0.948025  0.700020 -0.030588 -1.012356  1\n",
            "4 -1.095295  0.615735  1.933787 -1.191877  1\n",
            "          X0        X1        X2        X3  Y\n",
            "95  0.038127  1.789684 -1.411508 -0.359569  1\n",
            "96  0.730680  0.599829 -0.188470 -0.036158  1\n",
            "97 -1.310219  0.319369 -1.119420  0.792801  1\n",
            "98  0.282788 -0.685613 -0.867979  1.786075  1\n",
            "99  0.793763  0.659452 -1.854807  0.768982  1\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   X0      100 non-null    float64\n",
            " 1   X1      100 non-null    float64\n",
            " 2   X2      100 non-null    float64\n",
            " 3   X3      100 non-null    float64\n",
            " 4   Y       100 non-null    int64  \n",
            "dtypes: float64(4), int64(1)\n",
            "memory usage: 4.0 KB\n",
            "None\n",
            "               X0          X1          X2          X3           Y\n",
            "count  100.000000  100.000000  100.000000  100.000000  100.000000\n",
            "mean     0.082983   -0.040723    0.011074   -0.139438    0.880000\n",
            "std      0.856162    0.865326    1.087033    0.999314    0.326599\n",
            "min     -2.374033   -1.975697   -2.071927   -2.470433    0.000000\n",
            "25%     -0.432642   -0.705888   -0.724907   -0.668006    1.000000\n",
            "50%      0.136361    0.071524    0.039644   -0.098377    1.000000\n",
            "75%      0.687297    0.595783    0.627224    0.555533    1.000000\n",
            "max      2.379336    1.958292    2.515437    2.166023    1.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT6rOQl9ETi7",
        "colab_type": "text"
      },
      "source": [
        "Data generation for K-means"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZugniEfsFFr2",
        "colab_type": "code",
        "outputId": "cb3004cf-f177-47db-a8a2-ef304c21f5bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        }
      },
      "source": [
        "X_a= -2 * np.random.rand(100,2)\n",
        "X_b = 1 + 2 * np.random.rand(50,2)\n",
        "X_a[50:100, :] = X_b\n",
        "plt.scatter(X_a[ : , 0], X_a[ :, 1], s = 50)\n",
        "plt.show()\n",
        "data_kmeans = {'X0': X_a[:,0],'X1':X_a[:,1]}\n",
        "kmdf = pd.DataFrame(data_kmeans)\n",
        "print(kmdf.head())\n",
        "print(kmdf.tail())\n",
        "print(kmdf.info())\n",
        "print(kmdf.describe())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAflUlEQVR4nO3df2wc53kn8O+zuyRFUXYNW7ItxaKZuq5lQbWcmhTj9s5pdQoqpdIZTVAouZwd2UlVGBegBQJEPiU4oXKjs1O0wKEp6nMdW3FiRC2atmnpyK500ckJzjYpBbYjUz8a6yjZFf1DVmWFlLTk7j79g1yaXM7Mzs68M/O+u98PIFjaXc6+s/Q+887zPu/7iqqCiIjclcu6AUREFA8DORGR4xjIiYgcx0BOROQ4BnIiIscVsnjTxYsXa09PTxZvTUTkrMOHD59V1SW1j2cSyHt6enDo0KEs3pqIyFkicsrrcaZWiIgcx0BOROQ4BnIiIscxkBMROS6TwU4iorjGiiUMvHIGI++No+eaLmxcvQyLOlozpMU+axFZAOB5AB3Tx/tbVd0R97hERH6GRs5hy5ODUAUuTpSxsD2Ph54Zxu771qCv5+qsmzcjrYuNxF39UEQEQJeqjolIG4AfA/gDVX3R72d6e3uV5YdEFMVYsYT+XfsxXizPe66rI4/B7evQZSBYNhqEa1+/7KpOPPD04TkXGxHEutiIyGFV7a19PPbZ6tSVYGz6n23Tf7g2LhElYuCVM/Drf6oCA6+ewea+7ljv0WiPv/b1nW05XJqszHnNxYmpC8+WJweNXWyqjAx2ikheRF4G8A6Afar6ksdrtorIIRE59O6775p4WyJqQSPvjc8ExVoXJ8r4wU/fwsN7j2LP4GmMFUsNH//tC5fx2cdfxHixPPM+FyfKGC+WseXJQYzXHHOsWJp+/IPX1wbx2aoXG5OMBHJVLavq7QBuALBGRFZ5vOYxVe1V1d4lS+bNMCUiCqXnmi4sbM/7Pv/C62fx6MGT2DkwjP5d+zE0ci70sYdGzuGurx/ARMm7y+8VhIPuELxcnChj5OzF8D8QgtHyQ1U9D+AAgPUmj0tEVLVx9TKI+D8/UZ6KqkG9aC/VnnWx5N+b9grCQXcIXha259GzeGHo14cRO5CLyBIRuWr6750APg7gWNzjEhF5WdRRwO771qCrIz/TM2/P+0f2sKmMMD1rryBc7w6hlgiw8bZloV8fhols+1IA3xKRPKYuDH+jqgMGjktEFsuyjruv52oMbl+HgVfPYOTsRQyPvo+DJ856vjZsKiNMz9orCG9cvQwPPTMcqt1d7fnpi5DZz8lE1cqrAD5ioC1E5Agb6ri7OgrY3NeNsWIJ/+MfjqCQE5Qq87vUYVMZ1Z61XzBvL4hnEK7eIWx5chCTpcpMamfez+cF2zbcksjnwyn6RNQQryqNRvPRpgyNnEP/rv3Ye2TUM4gD4VMZQbn3jkIOP/7yWt8gXL1DuPOma3yPP1FWjJ4v1m1HFAzkRNSQMHXcaZh9QfEq9+tsy6OrI3wqwyv3vrB96hjf+UI/rr1yQeDPd3UUsGHVUt98eRKDnFWtuTABkeOyzE/Xq+M2XVrnJ+iCUsgBn/iV67Hz7lUN5aNrc+89ixdi423LQh8jKF+exCBnFQM5kWOyzk8H5ZKT7HXWCrqglCrAtVcsiDSoWM29RzE7X+41Nd/0IGcVAzmRQ2anE6qSnPrtJateZy1bLii14vbqo2COnMghNuSng3LJSfY6awUNTqZ5QfFS7dVv27ACm/u6E/9M2CMncogt+el6vc40cvhZpTGqbFoPnYGcyCE2pRP8cslp5vCzSGMA2Y9T1Iq9HnkUXI+cKJq01uKOyvb2mZDlOfqtR84cOZFDbMlP+7Ehh580G8/R7UsjUQvq67kaB770G3jk2WN4/d0x3LRkEbatX1F3wkoa0srhs45+LgZyIsfU5mdPvD2GZ197y4r9KtPI4Wedn7ZpnKKKqRUih9i0zomXpEsCbTh/G8seGciJHGJjfna2pHP4Npz/oo4Ctq1f4fnctvUrMhmnYGqFyCE25mdrJVkSaMP5jxVLeORZ771zHnn2GD71qzekWk8PMJATOSUoP9ueF1z/C9kPeALx1isB/AOgDfnpMHcFm/u6U83lM5ATOSRonZOJsuKRvUcxev4SIMh8tmFUQQHQhnVewtwVpL0mDnPkRA6ZyUH7rHl9cbKCR58/GXkX+azVG8wUIPM6+qVXLvDdI7R6V5B2Lp+BnMgxfT1X48vrbwnccBiwq5olrDABsJqD37FpJR742E3YsWklBrevS6X0cGjkHL7+3HHf7dyqdwVp5/LduuciIgDA6PuXfYNJrdl5W9uFDYBxc/BRzNwt+LRvYXtu5q4g7Vw+e+REDqoGijBsqWYJI+i8slxjHAi+W2jPCx5cf+vMXUHateYM5EQOCgoUtbIOgI2wcbJNVdDdwkRZMfr+5TmP3dN/I9ryMpMCSzKXz0BO5CCviTd+sg6AjbB5UbCwdwtDI+fQv2s/nnrxFCan01+FHHDvnTcmlsvnMrZEDhsvlmYm3igUT70wAkDmbbIQNnjYslnC7PNKa43xesIsX6tAokvc+i1jy0BO1ETiBECv+u1GLwTNrt5ntGfwNHYODPsOcu7YtDLWIK1fIGfVClETiVrNYcOmzvXYcLdQLX383uE38H+OvQtAsXbFdbh16ZUAsltCgIGciEJPO89K1kvXzjY8egGPPHd8pi1DI/+Grz93DLvvW5PZEgIc7CQiKxaj8mPD0rVh27J2xbUB1USKy5MVPLz3KPYMnsaYwXYzkBORs/XbaS/dW68tB46/41l1s6Ath4pOrY6YxPIJDORE5Gz9dtp3C2HaUruEwIPrb0FeBJcnK4ndUTCQE1FT1G/b1JbqoPO2DSvQXsjDrzbQ1B1F7N+OiCwH8BSA6wAogMdU9X/FPS4RpSvJDSHisGHp2jhtSeOOwsRvqATgS6r6ExG5AsBhEdmnqt5nS0TWilK+mHRZYPVuwa9+O80LTZS2pFHJYnxCkIh8H8A3VHWf32s4IYioOaQ5icim2Z6NtCXMjNCw55HKzE4R6QHwPIBVqnqh5rmtALYCQHd39x2nTp0y9r5ElD6TAarZmbrgJT6zU0QWAfgegD+sDeIAoKqPAXgMmOqRm3pfIporrRmQtk8isknS4w9GjiIibZgK4k+r6t+ZOCYRNS7NGZA2lQW6IMnNMGKXH4qIAPgmgKOq+mfxm0REUaQ9A9KmssBWZ6KO/NcB3ANgrYi8PP3nEwaOS0QNSHsGpM2TiOIaK5awZ/B0ItPpkxA7taKqPwYQcq8SIkpK2qkOm8oCTbJpga6w3PykiWieLFbes3USUVQuLOfrxb4WEVEkWc2AzGJH+6S4WonDtVaIHBKUu7V5vRRXuFqJw98skSPC5G6bLdWRhtl19+9cKKKzLYdLk5V5r7O5Eoe/XSIHNJK7baZUR9JqL46dbXnPIA58kJ6yYcu5WgzkRA5wNXdrM6+L46XJD/5e7ZnPrsQZHr1gZUULAzmRA1zN3dos6OLY2ZbHJ37lelx7xYKZ9JQC89aWsaWihYGcyAFZbepruzhpjqCL46XJMq69YgG2bVgx89iewdPW3hUxkBM5wKbNFWwRd+JOoxdHm++KWH5I5IBmLy1sdEp83HVlxoolFCfLmCwHD2zOZvPaMm7/9olaSFBpoY2VFGFF6VnHGfyd/X6T5bkHCVpiwOa7Ijd+00QEwLu00MW1QaqiTomPmubwer+qQg54cP0KfOqOGzzf0+a1ZRjIiRzm4togtRNwKt7ZjcCeddTB36CefHshj462XODnZeuEK7t+w0TUENfqy2vvHgo5oOQTyIN61lHTHCYGLG2ccMXBTiKH2VxJUctrgNIviAPBPeuog782D1jGwR45kcNcqi8PunvwIgAuT5bx8N6jngO4UdIcNg9YxsFATuQwlwJT0N0DABRyglJFUcgJRIByRfHIs8cDB3CjpDnu+eiNePxHJ5ETwURZrRmwjIOpFSKHuVRfHpTWaM8LFDqdM1dMlhWXSxWje48OjZxD/679eOqFUzMpnba84N47b8Tg9nXWV/gEEW3kXseQ3t5ePXToUOrvS2SruHXg48WSdZUUtcaKpXlrlTRqYXseOzatbLgXHvTeXR15K6t7vIjIYVXtrX3c/pYTNTkTdeC1KYbqTEmbJgh51WF3tuUxWa5AVVEO0aeMOoDrWnVPoxjIiTKURB24zROEZg9QvvD6e/jBkdHQQRyoP4Drd2fjUnVPFAzkRBky3VOMc2FIa5p/V0cBv33bMuwcGMZEqbHUbtAAbtAFzKXqnig42EmUIdM9xTAXBi/VgcCdA8N49OBJ7BwYRv+u/RgaOdfQ+5top5d6A7j1FtFau+JaiHgf27bqnijYIyfKkOmeYpQLQxbT/OuXIgLthRzuvbMHAqk7gFvvAnbg+DvWrpNigtutJ3Kc6TrwKBeGLAYCg9pZyAnuvn0Zdt69KnSADXMB29zXbeU6KSYwtUKUIdN14BtXL2s4hZDFQGBQOzvacg0FcSD81Ptqdc+2DSuwua+7KYI4wB45UeZMrqgXZanVLAYCTS8JG+XOxuU13GtxQhBRE2pkglAak2X8gmbUiUxexzvqscN99cJQW3bpVeHi91qb+E0IYiAnotCBLUov1nTQDDreyqVX1r0wuDzLk4GcyGFppAHq9Y6jBGTTQdPE8fYMnsbOgWHfVFKUJQDSwin6RI5Ka6am10qC1QvIibd/ju+8dGrOBJ4wJYqmK2JMHK8ZZ3kykBNZLMut3GovIH6CAqjpoGnieM04y9NI+aGIPCEi74jIERPHI6IpUWdqxuU1U9JPUAA1vSOPieNFKdG0nak68t0A1hs6FhFNyyoN0MgU+qAAajpomjieS2u4h2Wkxar6vIj0mDgWEX0gqzRAvSn0swUFUNP14qaOZ7J23waptVpEtgLYCgDd3XaOCBPZJqut3IIuIFVhA6jpoGnqeFG2ibOVsfLD6R75gKquqvdalh8ShZfF5JWgMr+OQg73fPRG3HzdIqd7sS5i+SGRo7JIA9RLYdg8+7EVMZATOSCLNECz5ZGbmZHfiIh8F8BvAFgsIm8C2KGq3zRxbCLKTjPlkZuZqaqVz5g4DhERNY7rkRMROY6BnIjIcQzkRESOYyAnInIcAzkRkeMYyImIHMdATkTkOAZyIiLHMZATETmOgZyIyHEM5EREjmMgJyJyHAM5EZHjGMiJiBzHQE5E5DgGciIixzGQExE5joGciMhxDORERI5jICcichwDORGR4xjIiYgcx0BOROQ4BnIiIscxkBMROY6BnIjIcQzkRESOYyAnInIcAzkRkeMYyImIHMdATkTkOCOBXETWi8hxEfmZiDxo4phERBRO7EAuInkAfwFgA4CVAD4jIivjHpeIiMIpGDjGGgA/U9WTACAiewDcDWDYwLEJwFixhIFXzmDkvXH0XNOFjauXYVGHiV8dETUDE9HgQwDemPXvNwH0175IRLYC2AoA3d3dBt62NQyNnMOWJwehClycKGNhex4PPTOM3fetQV/P1Vk3j4gskNpgp6o+pqq9qtq7ZMmStN7WaWPFErY8OYjxYhkXJ8oApoL5eLE8/Xgp0jH3DJ7Gw3uPYs/gaYxFOAYR2cVEj/xfASyf9e8bph9rWmmlOgZeOQNV7+dUgYFXz2Bzn/fdjVcbj45eYO+eqAmZiD5DAG4WkQ9jKoB/GsB/MXDcQFnljeOmOhpp98h74zM98VoXJ8oYOXsxfBsHhlFWxeXJypxjAMCWJwcxuH0duhr4/Ji3J7JH7G+eqpZE5IsAngOQB/CEqr4Wu2UB4gTTOAFodqqjqpFg2Gi7e67pwsL2vGcwX9ieR8/ihQ210U+93n3c8yCiZBnJkavqD1T1l1X1JlX9molj+omTNx4aOYf+Xfuxc2AYjx48iZ0Dw+jftR9DI+dCvXeYVIfJdm9cvQwi3scTATbetqyhNvoJ6t3Xipu3Z46eyDznZnZGDaYmBg6jpjqitntRRwG771uDro48FrbnAUz1xLs68tOPz+/9B7XRj1/v3kuci1ncCykReXMuqRk1mMYZOKyKkuqI2+6+nqsxuH0dBl49g5GzF9GzeCE23rbMN4UT1EY/fr17YH4q6sTbP490HnHTUkTkz7lvTtRgWi+Q/uCnb+H/nw3Om29cvQwPPeM9zykoGMZpNwB0dRRC56+D2rigLYecAIDM5LZF4Nu798qFlyuKjkIOxVJl3uuDzsPEhZSIvDkXyKMG03o91RdeP4uDJ95Fe17w1X/4Kb7wH38RX1x785yAXk111Aa3oGAYt92NqtfGlUuvDNW7jzJoGnQecdJSRBTMuUAeNZgGBVIAmCjrnP8+evAkvv3CKey+f24lRqOpjrjtjqJeG8P0fIN60B2FHBSKQi4X+jzi3JEQUTDRRkscDOjt7dVDhw7FOsZ4sdRwMK1NFbTnZSZw++nqyBvN30ZpdxYe3nsUjx486fv8F/7Dh3HzdYtCn8dYsYT+Xfvn9PCrTH/GRM1KRA6ram/t485+cxrJG1fV9lSHR9/HwRNnA3/GdP42SruzUK8HffN1ixo6jzTvSIhaTct9e2YH0j2DpzE08m+Bud9Wzd8mkdOPmpYiomDO1ZGbFDThpqpV87dRatjDqF5It21Ygc193QziRAa09LeoGqw+98RLuDgxv5wOMFtR4hr2oInc4Oxgp0njxRL+9J+P41v/7xQUiooCnW155HLg+iFEZA2/wc6WTq1UDY9ewF8fegPtBUFFgUIOKGsFf/lf72AQJyLrtXwgnz3x5dL0Eq+lCjBRUjzwncMYL5a40BMRWa3lk531po7/+Q//Bd9+8RSXbCUia7V8j7ze1PHHf3TS6FZrRESmtXwgr0588dKeF+R86hPrLdlKRJSWlg/kQbXkCvhO4W/ViUJEZJ+WD+SzJ750tk19HIUc0F4Q3NN/o29vvVUnChGRfVo+kANTE1/+8rN3TJceCkoVoFIBvjN4GuVK9hOFWDVDREGcqVpJctf2sWIJDzx9eM5mCaWKApWptEpHQZBvYMlWk2zZ6DjJz5+I4nFiZqdXMKsGUxPBbM/gafzRPw3j0qR39Up7XvDVjbdi9Hwx1Wnqtiz9mvTnT0ThODuz08SmyfWMvDfuG8QBoKKKjkI+9YWe4mx0bEoanz8RxWN9IE8jmPVc04VCzn8ZxFIFmVSo2LA9mg0XEyIKZn0gTyOYbVy9DPmAQN7ZlsukQiWoxj2tqhkbLiZEFMz6QJ5GMFvUUcBf3Tsv7TQjl5NMlrINqnFPq2rGhosJEQWzPpCnFczu+uUleOrza9BeEBSmP5XOtlzsjRTiMLm5Q9QSxqQ+f5ZUEpnDqpUaNm6OHLdNcT+/50+8i9976hDKFUWporHXamcVDFE0flUrTgRywM4Aa6Paeu/fXHEt1v7p/41cwlgNupWK4tJkBYXcVKrp8c/14a6bl0Rqnw0llUQu8gvkznxjou4+30oTWbx6ujv+8TXf11erTvw+19mlh1WlCoDK1FrtUYJumCqYKL9nolbWnBFtmi2zItPgFXT9qk1mPx9UdZJE0GUVDJF51g92RtVqE1mCgq6felUn9YLudwffaHigklUwRObFCuQi8rsi8pqIVETEv34vA80+kaW26uPE2z+v2wOvVa/qJCjoAsDLb5zHzoFh9O/aj6GRc6He04aSSqJmEze1cgTAJwH8bwNtMaqZb+FrU0adbTlMlhU5mVnnK1DYhb82rl6Gh54ZDjxW9TPe8uRgqJx5taTSr2qFA51EjYv1rVHVowAgfl2sDC29ckHw81d1pNQSs7xy4dVNo8P4yPKr8Ok1y0NV/XgFXT+N5Mz7eq7G4PZ1rEIiMiS1b46IbAWwFQC6u5OvStB6Fxe17+ITRpRceNXC9jw+vWZ5QwOUs4PudwffwMtvnPd8XaN3OVGrkIhovrqBXET2A7je46mvqOr3w76Rqj4G4DFgqo48dAsjeuv9S4HPj75/OekmJCIoZVRP1Bx0NeiqwjcXz4FKouzUDeSqui6NhphWHahrtqATdF61Crmpum9TOeignLmAA5VEWWna8kNXqyPqrUESdF6zdbblcfftH8IDH7sJOzatxOD2dbFr56s58wVt8/+3KatiePRCrOMTUTSxpuiLyO8A+HMASwCcB/Cyqv5WvZ+LMkU/CtfW9BgaOYctTwxislzBRFnRnhe05XPYff/c9tZOm/eS1HT3sWIJa762Dxcn5r8vp9gTJcv5tVaicmWNlrFiCb1/vA+XPQLzgrYcDn/143PaXT2vF15/D3uPvIWcCC5NJn+x2jN4GjsHhn1TVjs2reQgJlFCnF9rJSrFVGmcQqf/a6e/PfymZxAHgMuTFXzv8Ju499d6Zh6rDkBu7uvG11K8WDVzfT6Rq5o6kLu01sqBY28HPv/DY+/MCeSzpVnK16yDyEQua9rBzlZbayUtrg4iEzWzpg3krq21svaWa4Ofv7Xxtb+TYHLXIiIyw7lvXdj1xV3L5X6qdzn+57PHfAc7P/WryzNolTdOsSeyi1PfPK+c986B13DvnT0AMCewu5bLXdRRwLc/34/PPfESSmWdKT8s5AXfur/fuiDJKfZE9nCm/HCsWEL/1/ZjPGBG4+zSu1uXXunklmKulEsSUfr8yg+dyZF/44f/EhjEgbmDmQI4mcut9nS3bViBzX3d1raTiOzhRJQYK5bw+I9Ohn797CVVmct1Ryvtr0pkkhPfkoFXziAngrDTeWYPZrqcy22lwOZSzT+RbZyICiPvjWOi3Fguf+kvBG8sYZvaoL3sqk488PThlghsQRtHh915iKiVOfHtaGTp1hmiDfVos+z9em3dVrsYlqnAZmMvP0zNv6t3VURpcCKQh9k7stZPTp3HI88eD9WjzfK2/u0Ll/HZx1/EROmDSBa0dVucwJbkeca5QLhW809kGyeqVrxmE7bn/Rfl7mzLYe+Rt0JNz290Kn+99cIbMTRyDnd9/cCcIF5P1MCW5JIFQyPn0L9rP3YODOPRgyexc2AY/bv2Y2jkXKifr95xebGx5p/INk4EcuCD2YQ7Nq3EAx+7CV/97VvR5fPlL6tOD47OVzs9v5Gp/HED1mzVwFoshd84GYge2JJassDEBYLrtxDF40wgB+bWWN/7ax/G7vu968Q3rFqKS5PhbtXD3tab7tFG3UQ5amBLKn1h4gLB9VuI4nH6G+K35sc/vXIG+4bfDjU9P+xUftMDcmE3Ue5sy8/bMCJKYEtqyQJTFwiu30IUnfPfEq868cBNgmt6tGFfa7pHW68Sp70gePxzfRg9f8lIYGvkM2mEyQuEyzX/RFlyKrUSViO36mFfa3pALigv3FHI4cdfXou7bl5ibLp+UukL5reJsufMollRNLIAVb3XjhVLxhfhymJz6CQW5XJtk2siV7Xs5ssmJRGwmmW1w2Y5DyKbNV0gz2qGIgMWEWWlqQI5b+WJqBU5vx55FTdVTpfJmaxElAzncgJcYCk9XFqWyA3O9ci5wFI6eOdD5A7nAnkrLbCUZVojqbVZiMg851IrSc1QTFqjVTZZpzV450PkDud65C4usNToqok2pDVa6c6HyHXOBXJg/pK2OzatxOD2dVYOwEUJyjakNTj1nsgd9nVfQ3JlgaUoVTY2pDWqdz5+9fo23vkQtapY30YR+RMAmwBMAHgdwH2qet5Ew5pFlKCc1JKzjeLSskRuiJta2QdglareBuAEgP8ev0nNJUqu2aa0xuzNPOKuwEhEyYgVyFX1n1W1muR9EcAN8ZvUXKIEZRcHdIkoOyYjwv0A/trg8ZpC1Fwz0xpEFFbdRbNEZD+A6z2e+oqqfn/6NV8B0Avgk+pzQBHZCmArAHR3d99x6tSpOO12DldNJKK4Elv9UES2APh9AP9JVUOVU7i6HjkRUZb8AnncqpX1AL4M4GNhgzgREZkVt2rlGwCuALBPRF4WkUcNtImIiBoQq0euqr9kqiFERBSNk1P0iYjoA5ls9SYi7wKIWrayGMBZg81xQSueM9Ca581zbg1Rz/lGVV1S+2AmgTwOETnkNWrbzFrxnIHWPG+ec2swfc5MrRAROY6BnIjIcS4G8seybkAGWvGcgdY8b55zazB6zs7lyImIaC4Xe+RERDQLAzkRkeOcDOQi8icickxEXhWRvxeRq7JuU9JE5HdF5DURqYhIU5dqich6ETkuIj8TkQezbk8aROQJEXlHRI5k3Za0iMhyETkgIsPT/2//QdZtSpqILBCRQRF5Zfqc/8jEcZ0M5GjNnYmOAPgkgOezbkiSRCQP4C8AbACwEsBnRGRltq1KxW4A67NuRMpKAL6kqisBfBTAf2uB33URwFpVXQ3gdgDrReSjcQ/qZCBvxZ2JVPWoqh7Puh0pWAPgZ6p6UlUnAOwBcHfGbUqcqj4P4FzW7UiTqo6q6k+m//5zAEcBfCjbViVLp4xN/7Nt+k/sihMnA3mN+wHszboRZMyHALwx699vosm/3ASISA+AjwB4KduWJE9E8iLyMoB3AOxT1djnbO0WNQ3sTFQC8HSabUtKmHMmajYisgjA9wD8oapeyLo9SVPVMoDbp8f2/l5EVqlqrLERawO5qq4Len56Z6KNmNqZqCmK4eudc4v4VwDLZ/37hunHqAmJSBumgvjTqvp3WbcnTap6XkQOYGpsJFYgdzK1Mmtnov/MnYmazhCAm0XkwyLSDuDTAP4x4zZRAkREAHwTwFFV/bOs25MGEVlSrbITkU4AHwdwLO5xnQzkaMGdiUTkd0TkTQB3AnhGRJ7Luk1JmB7E/iKA5zA1+PU3qvpatq1Knoh8F8ALAG4RkTdF5PNZtykFvw7gHgBrp7/HL4vIJ7JuVMKWAjggIq9iqtOyT1UH4h6UU/SJiBznao+ciIimMZATETmOgZyIyHEM5EREjmMgJyJyHAM5EZHjGMiJiBz37x9LUj40pombAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "         X0        X1\n",
            "0 -1.998213 -0.707948\n",
            "1 -0.695006 -0.856255\n",
            "2 -1.218669 -1.908412\n",
            "3 -0.976367 -0.692838\n",
            "4 -1.092268 -1.485779\n",
            "          X0        X1\n",
            "95  2.626060  2.910404\n",
            "96  1.191776  2.506523\n",
            "97  2.466889  1.361326\n",
            "98  1.008060  1.314374\n",
            "99  1.193339  2.698906\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   X0      100 non-null    float64\n",
            " 1   X1      100 non-null    float64\n",
            "dtypes: float64(2)\n",
            "memory usage: 1.7 KB\n",
            "None\n",
            "               X0          X1\n",
            "count  100.000000  100.000000\n",
            "mean     0.490596    0.520166\n",
            "std      1.734713    1.593996\n",
            "min     -1.998213   -1.908412\n",
            "25%     -1.066008   -0.967272\n",
            "50%      0.489311    0.469847\n",
            "75%      2.203338    1.997765\n",
            "max      2.972002    2.998650\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yIvruqbEdNg",
        "colab_type": "text"
      },
      "source": [
        "**Question** **3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLKbFU9CEdYL",
        "colab_type": "text"
      },
      "source": [
        "Linear Regression using gradient descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAgXrvNhFcwD",
        "colab_type": "code",
        "outputId": "98d383ef-002a-4c9f-d2c4-cbbf5a3c62b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "X = mlrdf.iloc[:,0].values\n",
        "#print(X)\n",
        "y = mlrdf.iloc[:,4].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y)**2\n",
        "  d1 = (-2/n) * sum(X * (y - y_p))\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "\n",
        "print(b1,b0)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.09192938596999284 0.1671968912686631\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZxbTuSOEp1j",
        "colab_type": "text"
      },
      "source": [
        "Logistic Regression using gradient descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU7Mr9tbFg-6",
        "colab_type": "code",
        "outputId": "894ae533-862d-4866-8d41-2c2ee9bb524c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "X1 = lrdf.iloc[:,0:4].values\n",
        "y = lrdf.iloc[:,4].values\n",
        "\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y,y_hat):\n",
        "  return -np.mean(y*np.log(y_hat) + (1-y)*(np.log(1-y_hat)))\n",
        "\n",
        "W = np.zeros((4,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y,A)\n",
        "  dz = A - y\n",
        "  dw = 1/m * np.matmul(X1.T,dz)\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "0.3666308033769872\n",
            "0.3663419087341604\n",
            "0.36605823821226124\n",
            "0.3657797236251914\n",
            "0.3655062971617172\n",
            "0.36523789136166196\n",
            "0.36497443909482863\n",
            "0.3647158735426071\n",
            "0.36446212818221746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QUCLPlVEuuL",
        "colab_type": "text"
      },
      "source": [
        "Linear Regression using L1 Regulrisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv1xezoKFl72",
        "colab_type": "code",
        "outputId": "455ca834-8b3a-4231-bebe-79fd871787c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "X = mlrdf.iloc[:,0].values\n",
        "y = mlrdf.iloc[:,4].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        "lam = 0.1\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y1)**2 + (lam * b1)\n",
        "  d1 = (-2/n) * sum(X * (y - y_p)) + lam\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "\n",
        "print(b1,b0)\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.08291966556512821 0.16708565784059595\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLMDVi72E61C",
        "colab_type": "text"
      },
      "source": [
        "Linear regression using L2 regularisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jpfw1ZXXFpTh",
        "colab_type": "code",
        "outputId": "e9b727cc-75f9-464e-9dc8-71b8ffc97ba4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "X = mlrdf.iloc[:,0].values\n",
        "y = mlrdf.iloc[:,4].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        "lam = 0.1\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y1)**2 + ((lam/2) * b1)\n",
        "  d1 = (-2/n) * sum(X * (y - y_p)) + (lam *b1)\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "\n",
        "print(b1,b0)\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.09149442368804636 0.16719329699558128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3gZvGxSFJoD",
        "colab_type": "text"
      },
      "source": [
        "Logistic regression using L1 regularisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEKk3XIeFs34",
        "colab_type": "code",
        "outputId": "77d809ca-42e8-47bf-c44b-b051dff1fe2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "X1 = lrdf.iloc[:,0:4].values\n",
        "y = lrdf.iloc[:,4].values\n",
        "lam = 0.1\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y,y_hat):\n",
        "  return -np.mean(y*np.log(y_hat) + (1-y)*(np.log(1-y_hat))) + (lam * (np.sum(W)))\n",
        "\n",
        "W = np.zeros((4,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y,A)\n",
        "  dz = A - y\n",
        "  dw = 1/m * np.matmul(X1.T,dz) + lam\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "-0.03178280325662741\n",
            "-0.426788232792591\n",
            "-0.8183007841045096\n",
            "-1.2063579134371736\n",
            "-1.5909973695750237\n",
            "-1.972257147117062\n",
            "-2.35017544186448\n",
            "-2.7247906082799536\n",
            "-3.0961411189730246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozhNbzapFQzA",
        "colab_type": "text"
      },
      "source": [
        "Logistic regression using L2 regularisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8Sa5r6QFwTu",
        "colab_type": "code",
        "outputId": "611f77fb-55e8-4161-8958-aa2082dbcd80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "X1 = lrdf.iloc[:,0:4].values\n",
        "y = lrdf.iloc[:,4].values\n",
        "lam = 0.1\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y*np.log(y_hat) + (1-y)*(np.log(1-y_hat))) + (lam * (np.sum(np.square(W))))\n",
        "\n",
        "W = np.zeros((4,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y,A)\n",
        "  dz = A - y\n",
        "  dw = 1/m * np.matmul(X1.T,dz) + lam * W\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "0.3669235649750355\n",
            "0.3674909265408073\n",
            "0.36859499016503666\n",
            "0.37020496636697525\n",
            "0.3722913285785769\n",
            "0.3748257705053223\n",
            "0.37778116481171525\n",
            "0.3811315230715335\n",
            "0.38485195692771734\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "761OTVJ6FYL8",
        "colab_type": "text"
      },
      "source": [
        "K means clustering algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KF3iQiGZFzf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class K_Means:\n",
        "    def __init__(self, k=2, tol=0.001, max_iter=300):\n",
        "        self.k = k\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "    def fit(self,data):\n",
        "\n",
        "        self.centroids = {}\n",
        "\n",
        "        for i in range(self.k):\n",
        "            self.centroids[i] = data[i]\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            self.classifications = {}\n",
        "\n",
        "            for i in range(self.k):\n",
        "                self.classifications[i] = []\n",
        "\n",
        "            for featureset in X:\n",
        "                distances = [np.linalg.norm(featureset-self.centroids[centroid]) for centroid in self.centroids]\n",
        "                classification = distances.index(min(distances))\n",
        "                self.classifications[classification].append(featureset)\n",
        "\n",
        "            prev_centroids = dict(self.centroids)\n",
        "\n",
        "            for classification in self.classifications:\n",
        "                self.centroids[classification] = np.average(self.classifications[classification],axis=0)\n",
        "\n",
        "            optimized = True\n",
        "\n",
        "            for c in self.centroids:\n",
        "                original_centroid = prev_centroids[c]\n",
        "                current_centroid = self.centroids[c]\n",
        "                if np.sum((current_centroid-original_centroid)/original_centroid*100.0) > self.tol:\n",
        "                    print(np.sum((current_centroid-original_centroid)/original_centroid*100.0))\n",
        "                    optimized = False\n",
        "\n",
        "            if optimized:\n",
        "                break\n",
        "\n",
        "    def predict(self,data):\n",
        "        distances = [np.linalg.norm(data-self.centroids[centroid]) for centroid in self.centroids]\n",
        "        classification = distances.index(min(distances))\n",
        "        return classification\n",
        "        \n",
        "colors = 10*[\"g\",\"r\",\"c\",\"b\",\"k\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PStCKV5zF4NF",
        "colab_type": "code",
        "outputId": "47240a9a-c404-45f7-989e-aa3004f3f25d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "X = kmdf.iloc[:,0:2].values\n",
        "clf = K_Means()\n",
        "clf.fit(X)\n",
        "\n",
        "for centroid in clf.centroids:\n",
        "    plt.scatter(clf.centroids[centroid][0], clf.centroids[centroid][1],\n",
        "                marker=\"o\", color=\"k\", s=150, linewidths=5)\n",
        "\n",
        "for classification in clf.classifications:\n",
        "    color = colors[classification]\n",
        "    for featureset in clf.classifications[classification]:\n",
        "        plt.scatter(featureset[0], featureset[1], marker=\"x\", color=color, s=150, linewidths=5)\n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qr1Azy0Fdsw",
        "colab_type": "text"
      },
      "source": [
        "**Question** **4**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrzqzNpWFful",
        "colab_type": "text"
      },
      "source": [
        "Linear Regression using OOPS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNkDve9wF-yS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class LinearRegressionModel():\n",
        "\n",
        "    def __init__(self, dataset, learning_rate, num_iterations):\n",
        "        self.dataset = np.array(dataset)\n",
        "        self.b = 0  \n",
        "        self.m = 0  \n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_iterations = num_iterations\n",
        "        self.M = len(self.dataset)\n",
        "        self.total_error = 0\n",
        "\n",
        "    def apply_gradient_descent(self):\n",
        "        for i in range(self.num_iterations):\n",
        "            self.do_gradient_step()\n",
        "\n",
        "    def do_gradient_step(self):\n",
        "        b_summation = 0\n",
        "        m_summation = 0\n",
        "        for i in range(self.M):\n",
        "            x_value = self.dataset[i, 0]\n",
        "            y_value = self.dataset[i, 1]\n",
        "            b_summation += (((self.m * x_value) + self.b) - y_value) \n",
        "            m_summation += (((self.m * x_value) + self.b) - y_value) * x_value\n",
        "        self.b = self.b - (self.learning_rate * (1/self.M) * b_summation)\n",
        "        self.m = self.m - (self.learning_rate * (1/self.M) * m_summation)\n",
        "      \n",
        "    def compute_error(self):\n",
        "        for i in range(self.M):\n",
        "            x_value = self.dataset[i, 0]\n",
        "            y_value = self.dataset[i, 1]\n",
        "            self.total_error += ((self.m * x_value) + self.b) - y_value\n",
        "        return self.total_error\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"Results: b: {}, m: {}, Final Total error: {}\".format(round(self.b, 2), round(self.m, 2), round(self.compute_error(), 2))\n",
        "\n",
        "    def get_prediction_based_on(self, x):\n",
        "        return round(float((self.m * x) + self.b), 2) # Type: Numpy float.\n",
        "\n",
        "def main():\n",
        "    school_dataset = np.genfromtxt(DATASET_PATH, delimiter=\",\")\n",
        "    lr = LinearRegressionModel(school_dataset, 0.0001, 1000)\n",
        "    lr.apply_gradient_descent()\n",
        "    hours = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "    for hour in hours:\n",
        "        print(\"Studied {} hours and got {} points.\".format(hour, lr.get_prediction_based_on(hour)))\n",
        "    print(lr)\n",
        "\n",
        "if __name__ == \"__main__\": main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E3sqn-6FoIe",
        "colab_type": "text"
      },
      "source": [
        "Logistic Regression using OOPS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewDV2yxCFudG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LogisticRegression:\n",
        "  def __init__(self, learning_rate, num_iters, fit_intercept = True, verbose = False):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.num_iters = num_iters\n",
        "    self.fit_intercept = fit_intercept\n",
        "    self.verbose = verbose\n",
        "  def __add_intercept(self, X):\n",
        "    intercept = np.ones((X.shape[0],1))\n",
        "    return np.concatenate((intercept,X),axis=1)\n",
        "  def __sigmoid(self,z):\n",
        "    return 1/(1+np.exp(-z))\n",
        "  def __loss(self, h, y):\n",
        "    return (-y * np.log(h) - (1-y) * np.log(1-h)).mean()\n",
        "  \n",
        "  def fit(self,X,y):\n",
        "    if self.fit_intercept:\n",
        "      X = self.__add_intercept(X)\n",
        "    self.theta = np.zeros(X.shape[1])\n",
        "    \n",
        "    for i in range(self.num_iters):\n",
        "      z = np.dot(X,self.theta)\n",
        "      h = self.__sigmoid(z)\n",
        "      gradient = np.dot(X.T,(h-y))/y.size\n",
        "      \n",
        "      self.theta -= self.learning_rate * gradient\n",
        "      \n",
        "      z = np.dot(X,self.theta)\n",
        "      h = self.__sigmoid(z)\n",
        "      loss = self.__loss(h,y)\n",
        "      \n",
        "      if self.verbose == True and i % 1000 == 0:\n",
        "        print(f'Loss: {loss}\\t')\n",
        "  def predict_probability(self,X):\n",
        "    if self.fit_intercept:\n",
        "      X = self.__add_intercept(X)\n",
        "    return self.__sigmoid(np.dot(X,self.theta))\n",
        "  def predict(self,X):\n",
        "    return (self.predict_probability(X).round())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zjtp6HBDFzfO",
        "colab_type": "text"
      },
      "source": [
        "K-means clustering using OOPS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJPOWQtMF6Ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class K_Means:\n",
        "    def __init__(self, k=2, tol=0.001, max_iter=300):\n",
        "        self.k = k\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "    def fit(self,data):\n",
        "\n",
        "        self.centroids = {}\n",
        "\n",
        "        for i in range(self.k):\n",
        "            self.centroids[i] = data[i]\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            self.classifications = {}\n",
        "\n",
        "            for i in range(self.k):\n",
        "                self.classifications[i] = []\n",
        "\n",
        "            for featureset in X:\n",
        "                distances = [np.linalg.norm(featureset-self.centroids[centroid]) for centroid in self.centroids]\n",
        "                classification = distances.index(min(distances))\n",
        "                self.classifications[classification].append(featureset)\n",
        "\n",
        "            prev_centroids = dict(self.centroids)\n",
        "\n",
        "            for classification in self.classifications:\n",
        "                self.centroids[classification] = np.average(self.classifications[classification],axis=0)\n",
        "\n",
        "            optimized = True\n",
        "\n",
        "            for c in self.centroids:\n",
        "                original_centroid = prev_centroids[c]\n",
        "                current_centroid = self.centroids[c]\n",
        "                if np.sum((current_centroid-original_centroid)/original_centroid*100.0) > self.tol:\n",
        "                    print(np.sum((current_centroid-original_centroid)/original_centroid*100.0))\n",
        "                    optimized = False\n",
        "\n",
        "            if optimized:\n",
        "                break\n",
        "\n",
        "    def predict(self,data):\n",
        "        distances = [np.linalg.norm(data-self.centroids[centroid]) for centroid in self.centroids]\n",
        "        classification = distances.index(min(distances))\n",
        "        return classification\n",
        "        \n",
        "colors = 10*[\"g\",\"r\",\"c\",\"b\",\"k\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yN0_15Ic8jRv",
        "colab_type": "text"
      },
      "source": [
        "**Question** **1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyPZXiePUfl5",
        "colab_type": "code",
        "outputId": "9e86ce10-86c4-4bc1-bdcc-aac415080ccd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def roll_dice(prob=None):\n",
        "    if not prob:\n",
        "        return np.random.choice(a=[1,2,3,4,5,6])\n",
        "    else:\n",
        "        return np.random.choice(a=[1,2,3,4,5,6],p=prob)\n",
        "           \n",
        "def iterate(n=1000,prob=None):\n",
        "    reached=0\n",
        "    for _ in range(n):\n",
        "        throws=250\n",
        "        pos=0\n",
        "        while throws:\n",
        "            throws-=1\n",
        "            step=roll_dice(prob)\n",
        "            if pos>60:\n",
        "                reached+=1\n",
        "                break\n",
        "                \n",
        "            if step in {1,2}:\n",
        "                pos-=1\n",
        "            elif step in {3,4,5}:\n",
        "                pos+=1\n",
        "            else:\n",
        "                step=roll_dice(prob)\n",
        "                pos+=step\n",
        "    print(reached/n)\n",
        "iterate() #without probability weights in 1000 iterations\n",
        "iterate(prob=[0.2,0.3,0.2,0.1,0.1,0.1]) #with probability wieghts in 1000 iterations\n",
        "\n",
        "iterate(1000)\n",
        "iterate(1000,[0.2,0.3,0.2,0.1,0.1,0.1])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "0.324\n",
            "1.0\n",
            "0.315\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}